{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define the NER tag mapping\n",
    "ner_tags_mapping = {\n",
    "    'employerName': 0,\n",
    "    'employerAddressStreet_name': 1,\n",
    "    'employerAddressCity': 2,\n",
    "    'employerAddressState': 3,\n",
    "    'employerAddressZip': 4,\n",
    "    'einEmployerIdentificationNumber': 5,\n",
    "    'employeeName': 6,\n",
    "    'ssnOfEmployee': 7,\n",
    "    'box1WagesTipsAndOtherCompensations': 8,\n",
    "    'box2FederalIncomeTaxWithheld': 9,\n",
    "    'box3SocialSecurityWages': 10,\n",
    "    'box4SocialSecurityTaxWithheld': 11,\n",
    "    'box16StateWagesTips': 12,\n",
    "    'box17StateIncomeTax': 13,\n",
    "    'taxYear': 14,\n",
    "    'OTHER': 15  # Assuming OTHER is used for non-tagged elements\n",
    "}\n",
    "\n",
    "# Function to perform natural sorting\n",
    "def natural_sort_key(s):\n",
    "    # Split the filename into parts (numbers and text) to sort numerically and alphabetically\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# Set the directory path containing TSV files\n",
    "folder_path = '/home/aswin/Desktop/Infrrd/dataset__/dataset/train/boxes_transcripts_labels'\n",
    "output_file = '/home/aswin/Desktop/Infrrd/output.txt'  # Output file path\n",
    "\n",
    "# Initialize the id counter\n",
    "id_counter = 0\n",
    "\n",
    "# Get the list of TSV files and sort them naturally\n",
    "file_list = sorted(\n",
    "    [f for f in os.listdir(folder_path) if f.endswith('.tsv')],\n",
    "    key=natural_sort_key\n",
    ")\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_file, 'w') as out_file:\n",
    "    # Iterate through each TSV file in the sorted list\n",
    "    for filename in file_list:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        base_filename = filename.replace('.tsv', '.jpg')\n",
    "        \n",
    "        # Load the TSV file without headers and handle quotes correctly\n",
    "        df = pd.read_csv(file_path, sep=',', header=None, names=['start_index', 'end_index', 'x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right', 'transcript', 'field'])\n",
    "        \n",
    "        # Remove quotes from the transcript column if they exist\n",
    "        df['transcript'] = df['transcript'].str.replace('\"', '')\n",
    "        \n",
    "        # Prepare the data structure\n",
    "        data = {\n",
    "            'id': id_counter,  # Use the current id counter value\n",
    "            'file_name': base_filename,  # Use the extracted and modified file name\n",
    "            'tokens': df['transcript'].tolist(),\n",
    "            'bboxes': df[['x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right']].values.tolist(),\n",
    "            'ner_tags': [ner_tags_mapping.get(tag, -1) for tag in df['field'].tolist()]  # Map fields to NER tags\n",
    "        }\n",
    "        \n",
    "        # Write the dictionary as a string to the output file\n",
    "        out_file.write(str(data) + '\\n')  # Writes each data dictionary on a new line\n",
    "        \n",
    "        # Increment the id counter for the next file\n",
    "        id_counter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split into /home/aswin/Desktop/Infrrd/train.txt and /home/aswin/Desktop/Infrrd/test.txt.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File paths\n",
    "input_file = '/home/aswin/Desktop/Infrrd/output.txt'\n",
    "train_file = '/home/aswin/Desktop/Infrrd/train.txt'\n",
    "test_file = '/home/aswin/Desktop/Infrrd/test.txt'\n",
    "\n",
    "# Step 1: Read data from output.txt\n",
    "with open(input_file, 'r') as file:\n",
    "    data = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Step 2: Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(data, random_state=21, test_size=0.3)\n",
    "\n",
    "# Step 3: Write train data to train.txt\n",
    "with open(train_file, 'w') as file:\n",
    "    for line in train_data:\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "# Step 4: Write test data to test.txt\n",
    "with open(test_file, 'w') as file:\n",
    "    for line in test_data:\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "print(f\"Data successfully split into {train_file} and {test_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
